{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "import numpy as np\n",
    "\n",
    "def edgedp_compute_global_sens(G, Gstat, query_type, k):\n",
    "    num_nodes = Gstat.num_nodes\n",
    "    if query_type == \"triangle\":\n",
    "        return num_nodes-2\n",
    "    elif query_type == \"kstar\":\n",
    "        return 2 * comb(num_nodes-2, k-1)\n",
    "    elif query_type == \"kclique\":\n",
    "        return comb(num_nodes-2,k-2)\n",
    "    elif query_type == \"ktriangle\":\n",
    "        return comb(num_nodes-2,k) + 2*(num_nodes-2)*comb(num_nodes-3,k-1)\n",
    "    else:\n",
    "        print(query_type, \"is unspecified\")\n",
    "        return -1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgedp_compute_local_sens(G, Gstat, query_type, k):\n",
    "    ls = 0.0 \n",
    "    num_nodes = Gstat.num_nodes\n",
    "    if query_type == \"triangle\":\n",
    "        ls = Gstat.max_num_common \n",
    "        return ls\n",
    "    elif query_type == \"kstar\":\n",
    "        bucket = [-1] * num_nodes # bucket: the common neighbor sizes \n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i+1, num_nodes):\n",
    "                xij = int(G.has_edge(i,j))\n",
    "                di = max(G.degree[i],G.degree[j]) - xij\n",
    "                dj = min(G.degree[i],G.degree[j]) - xij \n",
    "                bucket[di] = max(bucket[di],dj)\n",
    "                \n",
    "        uppers = []\n",
    "        for i in reversed(range(num_nodes)):\n",
    "            if bucket[i] <0:\n",
    "                continue\n",
    "            if (len(uppers)==0) or uppers[-1][1] < bucket[i]:\n",
    "                uppers.append([i, bucket[i]])         \n",
    "        for p in uppers:\n",
    "            ls = max(ls, comb(p[0],k-1)+comb(p[1],k-1))\n",
    "\n",
    "        return ls\n",
    "    \n",
    "    elif query_type == \"kclique\":\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i+1, num_nodes):\n",
    "                ls  = max(ls, util.count_clique(G,Gstat.get_common_neighbors(min(i,j),max(i,j)),k-2))\n",
    "        return ls\n",
    "    \n",
    "    elif query_type == \"ktriangle\":\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i+1, num_nodes):\n",
    "                Aij = Gstat.get_common_neighbors(min(i,j),max(i,j)) # common neighbors of i and j\n",
    "                xij = int(G.has_edge(i,j)) # 1 if edge ij exists, 0 otherwise\n",
    "                \n",
    "                lsij = comb(len(Aij),k) # ktriangle sharing edge ij\n",
    "                for l in Aij: # l is connected to node i, j\n",
    "                    ail = Gstat.get_num_common_neighbors(min(i,l),max(i,l)) # ktriangle sharing edge il\n",
    "                    ajl = Gstat.get_num_common_neighbors(min(l,j),max(l,j)) # ktriangle sharing edge ij\n",
    "                    lsij = lsij + comb(ail-xij, k-1) + comb(ajl-xij,k-1)\n",
    "                ls = max(ls,lsij)\n",
    "        return ls\n",
    "    \n",
    "    else:\n",
    "        print(query_type, \"is unspecified\")\n",
    "        return ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers for computing the ladder function per graph query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following ladder functions uses local sensitivity at distance t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsd_triangle(G, Gstat, query_type, k):\n",
    "    num_nodes = Gstat.num_nodes\n",
    "    bucket = [-1] * num_nodes # bucket: the common neighbor sizes \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i+1, num_nodes):\n",
    "            # aij: the number of common neighbors of i and j\n",
    "            # aij = Gstat.get_num_common_neighbors(i,j)\n",
    "            aij = len(Gstat.common_neighbors['{},{}'.format(i,j)])\n",
    "            \n",
    "            #bij: the number of nodes connected to exactly one of i and j\n",
    "            bij = len(Gstat.connection_list[i]) + len(Gstat.connection_list[j]) - 2*aij - 2*int(G.has_edge(i,j))\n",
    "            # bij = G.degree[i] + G.degree[j] - 2*aij - 2*int(G.has_edge(i,j))\n",
    "            bucket[aij] = max(bucket[aij], bij)  \n",
    "    \n",
    "    uppers = []\n",
    "    for i in reversed(range(num_nodes)):\n",
    "        if bucket[i] <0:\n",
    "            continue\n",
    "        if (len(uppers)==0) or (i*2+bucket[i] > uppers[-1][0]*2 + uppers[-1][1]):\n",
    "            uppers.append([i, bucket[i]])\n",
    "    \n",
    "    gs = edgedp_compute_global_sens(G,Gstat,query_type,k)\n",
    "    \n",
    "    LSD = []\n",
    "    t = 0\n",
    "    \n",
    "    while 1:\n",
    "        lsd = 0\n",
    "        for p in uppers:\n",
    "            lsd = max(lsd, p[0]+ (t+min(t,p[1])) /2)\n",
    "        t +=1 \n",
    "        if lsd < gs:\n",
    "            LSD.append(lsd)\n",
    "        else: # converged\n",
    "            LSD.append(gs)\n",
    "            return LSD      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsd_kstar(G,Gstat,query_type,k):\n",
    "    num_nodes = Gstat.num_nodes\n",
    "    bucket = [-1] * num_nodes #bucket: the common neighbor sizes \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i+1, num_nodes):\n",
    "            xij = int(G.has_edge(i,j))\n",
    "            di = max(G.degree[i],G.degree[j]) - xij\n",
    "            dj = min(G.degree[i],G.degree[j]) - xij \n",
    "            bucket[di] = max(bucket[di],dj)\n",
    "    \n",
    "    uppers = []\n",
    "    for i in reversed(range(num_nodes)):\n",
    "        if bucket[i] <0:\n",
    "            continue\n",
    "        if (len(uppers)==0) or uppers[-1][1] < bucket[i]:\n",
    "            uppers.append([i, bucket[i]])   \n",
    "    \n",
    "    gs = edgedp_compute_global_sens(G,Gstat,query_type,k)\n",
    "    \n",
    "    LSD = []\n",
    "    \n",
    "    while 1:\n",
    "        lsd = 0\n",
    "        for p in uppers:\n",
    "            lsd = max(lsd, comb(p[0],k-1)+comb(p[1],k-1))\n",
    "            \n",
    "            if p[0] < num_nodes-2:\n",
    "                p[0] = p[0]+1\n",
    "            elif p[1] < num_nodes-2:\n",
    "                p[1] = p[1]+1\n",
    "            \n",
    "        if lsd < gs:\n",
    "            LSD.append(lsd)\n",
    "        else: # converged\n",
    "            LSD.append(gs)\n",
    "            return LSD    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsd_kclique(G,Gstat,query_type,k):\n",
    "    gs = edgedp_compute_global_sens(G,Gstat,query_type,k)\n",
    "    ls = edgedp_compute_local_sens(G,Gstat,query_type,k)\n",
    "    \n",
    "    LSD = []\n",
    "    lsd = ls \n",
    "    t = 0\n",
    "    \n",
    "    while 1: # loop until converge to gs\n",
    "        if lsd < gs:\n",
    "            LSD.append(lsd)\n",
    "        else:\n",
    "            LSD.append(gs)\n",
    "            return LSD   \n",
    "        lsd = lsd + comb(Gstat.max_num_common + t, k - 3)\n",
    "        t +=1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsd_ktriangle(G,Gstat,query_type,k):\n",
    "    gs = edgedp_compute_global_sens(G,Gstat,query_type,k)\n",
    "    ls = edgedp_compute_local_sens(G,Gstat,query_type,k)\n",
    "    \n",
    "    LSD = []\n",
    "    lsd = ls \n",
    "    t = 0\n",
    "    max_common_neighbors = Gstat.max_num_common\n",
    "    \n",
    "    while 1: # loop until converge to gs\n",
    "        if lsd < gs:\n",
    "            LSD.append(lsd)\n",
    "        else:\n",
    "            LSD.append(gs)\n",
    "            return LSD   \n",
    "        \n",
    "        lsd = lsd + 3* comb(max_common_neighbors+t, k-1) + (max_common_neighbors+t) * comb(max_common_neighbors+t,k-2)\n",
    "        t +=1 \n",
    "    \n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgedp_ladder_function(G, Gstat, query_type, k):\n",
    "    lsd = []    \n",
    "    if query_type == \"triangle\":\n",
    "        lsd = lsd_triangle(G,Gstat,query_type,k)\n",
    "    elif query_type == \"kstar\":\n",
    "        lsd = lsd_kstar(G,Gstat,query_type,k)\n",
    "        return lsd\n",
    "    elif query_type == \"kclique\":\n",
    "        lsd = lsd_kclique(G,Gstat,query_type,k)\n",
    "        return lsd\n",
    "    elif query_type == \"ktriangle\":\n",
    "        lsd = lsd_ktriangle(G,Gstat,query_type,k)\n",
    "        return lsd\n",
    "    else:\n",
    "        print(query_type, \"is unspecified\")\n",
    "    return lsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ladder Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgedp_ladder_mechanism_noise_sample(G, Gstat, query_type, k, epsilon, ladders, true_count):\n",
    "    #M: length of the ladder function\n",
    "    M = len(ladders)\n",
    "    \n",
    "    ranges = [0.0]\n",
    "    weights = [1.0] #the center's weight\n",
    "    \n",
    "    #rungs 1 to M\n",
    "    dst = 0.0 \n",
    "    for t in range(M):\n",
    "        weights.append(2*ladders[t]*np.exp(epsilon/2.0*(-t))) \n",
    "        ranges.append(dst)\n",
    "        dst = dst + ladders[t]\n",
    "        \n",
    "    #rung M+1\n",
    "    weights.append(2*ladders[-1]* np.exp(epsilon/2.0*(-M-1))/(1-np.exp(-epsilon/2.0)))\n",
    "        \n",
    "    ####the only part that involves randomness, may store the earlier results for evaluation over multiple runs \n",
    "\n",
    "    noisy_count = true_count\n",
    "\n",
    "    t = int(util.sample_prob_list(weights))\n",
    "\n",
    "    if t == 0:\n",
    "        return noisy_count\n",
    "\n",
    "    elif t <= M: # add/subtract noise of a uniformly distributed random integer in range[t]\n",
    "        flag = -1.0 # add or subtract? \n",
    "        if (np.random.uniform() > 0.5):\n",
    "            flag = 1.0\n",
    "        low = ranges[t-1]\n",
    "        delta = np.ceil(np.random.uniform() * (ranges[t] - ranges[t-1]))\n",
    "        noisy_count = flag * delta + true_count\n",
    "\n",
    "    else: # sample noise from geometric distribution\n",
    "        p = 1.0 - np.exp(-epsilon/2.0)\n",
    "        ext = np.random.geometric(p)\n",
    "        low = dst + ext * ladders[-1]\n",
    "        high = low + ladders[-1]\n",
    "        flag = -1.0 # add or subtract? \n",
    "        if (np.random.uniform()>0.5):\n",
    "            flag = 1.0\n",
    "        noisy_count = flag * np.random.randint(low, high+1) + true_count\n",
    "    \n",
    "    return noisy_count\n",
    "\n",
    "# end-to-end: ladder function paper: algorithm 1 \n",
    "def edgedp_ladder_mechanism(G, Gstat, query_type, k, epsilon):\n",
    "    true_count = count(G,Gstat,query_type,k)\n",
    "    \n",
    "    #ladders: ladder function evaluated on G\n",
    "    ladders = edgedp_ladder_function(G, Gstat, query_type, k)  \n",
    "    \n",
    "    return edgedp_ladder_mechanism_noise_sample(G, Gstat, query_type, k, epsilon, ladders, true_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth Sensitivity Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "\n",
    "def edgedp_smooth_sensitivity(lsd, beta):\n",
    "    ss = 0.0\n",
    "    for i in range(len(lsd)):\n",
    "        ss = max(ss, lsd[i]* np.exp(beta* (-1.0)* i))\n",
    "    return ss \n",
    "\n",
    "def edgedp_smooth_sensitivity_mechanism_non_ladder(G, Gstat, query_type, k, epsilon):\n",
    "    delta = 0.01 # Used only for ktriangle queries. Set according to Vishesh et al's evaluation parameters.\n",
    "    \n",
    "    true_count = util.count(G,Gstat,query_type,k)\n",
    "    \n",
    "    if(query_type == \"kstar\"):\n",
    "        ss = edgedp_smooth_sensitivity_kstar(G, Gstat, k, epsilon)\n",
    "    elif(query_type == \"ktriangle\"):\n",
    "        ss = edgedp_smooth_sensitivity_ktriangle(G, Gstat, k, epsilon)\n",
    "    else:\n",
    "        \n",
    "        #ladders: ladder function evaluated on G or LSD\n",
    "        ladders = edgeDP_LadderFunction(G,Gstat,query_type,k)  \n",
    "        \n",
    "        #M: length of the ladder function\n",
    "        M = len(ladders)\n",
    "    \n",
    "        ss = edgedp_smooth_sensitivity(ladders, epsilon/6.0)\n",
    "    \n",
    "    if(query_type == \"ktriangle\"):\n",
    "        noisy_count = edgedp_smooth_sensitivity_ktriangle_noise_sample(true_count, ss, Gstat.max_num_common, k , epsilon, delta)\n",
    "    else:\n",
    "        noisy_count = true_count + 6.0/epsilon * ss * np.random.standard_cauchy(1)  \n",
    "    \n",
    "    return noisy_count\n",
    "\n",
    "# overloaded method with ladders and true_count as input\n",
    "def edgedp_smooth_sensitivity_mechanism(G, Gstat, query_type, k, epsilon, ladders, true_count): \n",
    "    #M: length of the ladder function\n",
    "    M = len(ladders)\n",
    "    \n",
    "    ss = edgedp_smooth_sensitivity(ladders, epsilon/6.0)\n",
    "    \n",
    "    noisy_count = true_count + 6.0/epsilon * ss * np.random.standard_cauchy(1)  \n",
    "    return noisy_count\n",
    "\n",
    "def edgedp_smooth_sensitivity_kstar(G, Gstat, k, epsilon):\n",
    "        n = Gstat.num_nodes\n",
    "        beta = epsilon / 6\n",
    "        smoothSens = 0\n",
    "\n",
    "        degreeList = [0] * Gstat.num_nodes\n",
    "\n",
    "        # Sort nodes by degrees\n",
    "        degreeListStruct = [(i, G.degree[i]) for i in range(n)]\n",
    "        degreeListStruct = sorted(degreeListStruct, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "        ij_pairList = [(1,2)]\n",
    "        u1Nodes = []\n",
    "        u2Nodes = []\n",
    "\n",
    "        highestDegree = degreeListStruct[0][1]\n",
    "        secondHighestDegree = highestDegree\n",
    "        secondHighestStartIndex = 0\n",
    "        thirdHighestStartIndex = 0\n",
    "\n",
    "        u1 = -1\n",
    "        u2 = -1\n",
    "        v1 = -1\n",
    "        v2 = -1\n",
    "\n",
    "        for i in range(len(degreeListStruct)):\n",
    "            recordTuple = degreeListStruct[i]\n",
    "            if(recordTuple[1] < highestDegree):\n",
    "                secondHighestStartIndex = i\n",
    "                break\n",
    "            u1Nodes.append(recordTuple[0])\n",
    "\n",
    "        secondHighestDegree = degreeListStruct[secondHighestStartIndex][1]\n",
    "        for j in range(secondHighestStartIndex, len(degreeListStruct)):\n",
    "            recordTuple = degreeListStruct[j]\n",
    "            if(recordTuple[1] < secondHighestDegree):\n",
    "                thirdHighestStartIndex = j\n",
    "                break\n",
    "            u2Nodes.append(recordTuple[0])\n",
    "\n",
    "        # Get V1\n",
    "        for i in range(secondHighestStartIndex,len(degreeListStruct)):\n",
    "            recordTuple = degreeListStruct[i]\n",
    "            currNode = recordTuple[0]\n",
    "            for u1Node in u1Nodes:\n",
    "                if(u1Node in G.neighbors(currNode)):\n",
    "                    u1 = u1Node\n",
    "                    v1 = currNode\n",
    "                    break\n",
    "        # Get V2\n",
    "        for j in range(thirdHighestStartIndex, len(degreeListStruct)):\n",
    "            recordTuple = degreeListStruct[j]\n",
    "            currNode = recordTuple[0]\n",
    "            for u2Node in u2Nodes:\n",
    "                if(u2Node in G.neighbors(currNode)):\n",
    "                    u2 = u2Node\n",
    "                    v2 = currNode\n",
    "                    break\n",
    "\n",
    "        ij_pairList.append((u1, v1))\n",
    "        ij_pairList.append((u2, v2))\n",
    "\n",
    "        for t in range(2 * n - 2):\n",
    "            smoothSens_t = 0\n",
    "            for (i, j) in ij_pairList:\n",
    "                nodeI = i\n",
    "                nodeJ = j\n",
    "\n",
    "                d_i = degreeList[i]\n",
    "                d_j = degreeList[j]\n",
    "\n",
    "                xij = 0\n",
    "                if(nodeI in G.neighbors(nodeJ)):\n",
    "                    xij = 1\n",
    "\n",
    "                dprime_i = d_i - xij\n",
    "                dprime_j = d_j - xij\n",
    "\n",
    "                b_i = n - 2 - dprime_i\n",
    "                b_j = n - 2 - dprime_j\n",
    "\n",
    "                if(t <= b_i):\n",
    "                    currSens = comb(dprime_i + t, k - 1) + comb(dprime_j, k - 1)\n",
    "                elif (b_i < t < b_i + b_j):\n",
    "                    currSens = comb(n - 2, k - 1) + comb(dprime_i + t - b_j, k - 1)\n",
    "                elif (t >= b_i + b_j):\n",
    "                    currSens = 2 * comb(n - 2, k - 1)\n",
    "                else:\n",
    "                    print(\"Weird condition detected in ss_kstar()\")\n",
    "                    currSens = 0\n",
    "\n",
    "                smoothSens_t = max(smoothSens_t, currSens)\n",
    "\n",
    "            smoothSens = max(math.exp(-1 * t * beta) * smoothSens_t, smoothSens)\n",
    "\n",
    "        return smoothSens\n",
    "\n",
    "def edgedp_smooth_sensitivity_ktriangle(G, Gstat, k, epsilon):\n",
    "       # Note that this algorithm satsifies (epsilon,delta) differential privacy as specified in Vishesh et. al.\n",
    "        ls_max = 0\n",
    "        for i in range(Gstat.num_nodes + 1):\n",
    "            for j in range(i + 1, Gstat.num_nodes + 1):\n",
    "                common_neighbors = Gstat.common_neighbors['{},{}'.format(i, j)]\n",
    "                a_ij = len(common_neighbors)\n",
    "                \n",
    "                if((i, j) in G.edges()):\n",
    "                    x_ij = 1\n",
    "                else:\n",
    "                    x_ij = 0\n",
    "\n",
    "                ls = comb(a_ij, k)\n",
    "                for l in common_neighbors:\n",
    "                    a_il = len(Gstat.common_neighbors['{}, {}'.format(i,l)])\n",
    "                    a_lj = len(Gstat.common_neighbors['{}, {}'.format(l,j)])\n",
    "                    ls += comb(a_il - x_ij, k - 1) + comb(a_lj - x_ij, k - 1)\n",
    "\n",
    "                ls_max = max(ls_max, ls)\n",
    "\n",
    "        return ls_max\n",
    "\n",
    "def edgedp_smooth_sensitivity_ktriangle_noise_sample(true_count, local_sensitivity, amax, k, epsilon, delta):\n",
    "    # Note that this algorithm satsifies (epsilon,delta) differential privacy as specified in Vishesh et. al.\n",
    "    \n",
    "    epsilonp = epsilon /3\n",
    "    deltap = delta/3\n",
    "    \n",
    "    amax_noise = amax + stats.laplace.rvs(scale = 1/epsilonp) + (math.log(1/deltap) / epsilonp)\n",
    "       \n",
    "    B = (3 * comb(int(amax_noise), k-1)) + (amax_noise * comb(int(amax_noise), k-2))\n",
    "    \n",
    "    ls_noise = local_sensitivity + stats.laplace.rvs(scale = B / epsilonp) + ((B / epsilonp) * math.log(1/deltap))\n",
    "\n",
    "    return true_count + stats.laplace.rvs(scale = ls_noise / epsilonp)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Mechansim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgedp_laplace_mechanism(G, Gstat, query_type, k, epsilon, true_count):\n",
    "        \n",
    "    gs = edgedp_compute_global_sens(G, Gstat, query_type, k)\n",
    "    \n",
    "    scale =1.0* gs/epsilon\n",
    "    noisy = true_count + np.random.laplace(0.0, scale, 1)\n",
    "    \n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def H_linprog(edges, n, i):\n",
    "    # Computing Hi(P,M) = min q(M'(P'))\n",
    "\n",
    "    array = []\n",
    "    for j in range(n):\n",
    "        if (j+i) < n+1:\n",
    "            new_edges = edges.iloc[j:(j+i+1)]\n",
    "            edgelist = nx.from_pandas_edgelist(new_edges, 'f', 't', None)\n",
    "            temp = sum(nx.triangles(edgelist).values()) / 3\n",
    "            array.append(temp)\n",
    "\n",
    "    return np.min(array)\n",
    "\n",
    "def G_linprog(edges, n, i):\n",
    "    # computing Global Empirical Sensitivity Gi(P,M) = min GS(P', M')\n",
    "\n",
    "    real_edges = nx.from_pandas_edgelist(edges, 'f', 't', None)\n",
    "    real_count = sum(nx.triangles(real_edges).values()) / 3\n",
    "\n",
    "    array = []\n",
    "    for j in range(n):\n",
    "        if (j+i) < n+1:\n",
    "            new_edges = edges.iloc[j:(j+i+1)]\n",
    "            test = nx.from_pandas_edgelist(new_edges, 'f', 't', None)\n",
    "            temp = sum(nx.triangles(test).values()) / 3\n",
    "            array.append(real_count - temp)\n",
    "    \n",
    "    return real_count - np.min(array)\n",
    "\n",
    "\n",
    "def recursive(n, edges, query, eps1, eps2, theta, beta, mu, logging=False):\n",
    "    '''\n",
    "    @n: n is the total number of nodes. We assume their indices are\n",
    "    0, 1, ..., n-1\n",
    "    @edges: edges is a dataframe with columns ['f', 't'].\n",
    "    It is unlabeled, and edge is from small index to high index.\n",
    "    @query: 'triangle', '2-star' and so on\n",
    "    @epsilon: epsilon\n",
    "    @theta: theta\n",
    "    @beta: beta\n",
    "    @mu: mu\n",
    "    '''\n",
    "    #This is the general implementation of the algorithm\n",
    "    # The efficiency of this algorithm can be further\n",
    "    # improved by section 5.3\n",
    "\n",
    "    # 1. Get the output as a dataframe\n",
    "    if query == 'triangle':\n",
    "        test = nx.from_pandas_edgelist(edges, 'f', 't', None)\n",
    "        triangles = sum(nx.triangles(test).values()) / 3\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # 2. Compute the H and G sequence\n",
    "    H, G = [], []\n",
    "    if logging:\n",
    "        ranges = tqdm(range(n + 1))\n",
    "    else:\n",
    "        ranges = range(n + 1)\n",
    "    for i in ranges:\n",
    "        Hi = H_linprog(edges, n, i)\n",
    "        Gi = G_linprog(edges, n, i)\n",
    "        H.append(Hi)\n",
    "        G.append(Gi)\n",
    "\n",
    "    # 3. Compute delta\n",
    "    exp_series = np.exp(np.arange(n + 1) * beta) * theta\n",
    "\n",
    "    K = exp_series[exp_series >= G]\n",
    "    delta = np.min(K)\n",
    "\n",
    "    if logging:\n",
    "        print(f'delta is {delta}')\n",
    "\n",
    "    # # 4. Compute delta_hat\n",
    "    Y1 = np.random.laplace(scale=beta / eps1)\n",
    "    delta_hat = np.exp(mu + Y1) * delta\n",
    "\n",
    "    # # 5. Compute X\n",
    "    X = np.min(H + (n - np.arange(n + 1)) * delta_hat)\n",
    "    if logging:\n",
    "        print(f'X is {X}')\n",
    "\n",
    "    # # 6. Compute X_hat\n",
    "    Y2 = np.random.laplace(scale=delta_hat / eps2)\n",
    "    X_hat = X + Y2\n",
    "\n",
    "    rel_errors = (X_hat - triangles) / triangles\n",
    "    if logging:\n",
    "        print(\"rel_errors:\", rel_errors)\n",
    "\n",
    "    return X_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import timeit\n",
    "from util import *\n",
    "\n",
    "data_dir = \"data/\" # REPLACE WITH YOUR DATASET DIRECTORY\n",
    "data_key = 2\n",
    "data_file = data_dir + constants.DATASETS[data_key]\n",
    "\n",
    "\n",
    "queryTypeList = [\"triangle\", \"kstar\", \"kclique\", \"ktriangle\"]\n",
    "kList = [1, 3, 4, 2]\n",
    "\n",
    "algos = [\n",
    "            \"edgedp_laplace\", \n",
    "            \"edgedp_smooth\", \n",
    "            \"edgedp_ladder\",\n",
    "#              \"edgedp_recursive\" # this is slow, run only on small datases\n",
    "]\n",
    "\n",
    "\n",
    "for dataName in dataNames:\n",
    "    print(\"data: \", dataName)\n",
    "    datafile = dataDir+dataName #\"facebook_combined.txt\"\n",
    "    translated = datafile+\"-map.txt\"\n",
    "    if not os.path.isfile(translated):\n",
    "        #convert all nodes id to 0 to nodeNum\n",
    "        translate(datafile, translated)\n",
    "    else:\n",
    "        print(\"file exists\")\n",
    "\n",
    "    G=nx.read_edgelist(translated, nodetype=int)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    nodesNum = len(G.nodes()) #assume this is given\n",
    "    maxDeg = nodesNum -1  #assume this is given\n",
    "\n",
    "    Gstat = GraphStat(G)\n",
    "\n",
    "    all_errors = []\n",
    "    all_stds = []\n",
    "    for queryKey in range(len(queryTypeList)):\n",
    "        query_type = queryTypeList[queryKey]\n",
    "        k = kList[queryKey]\n",
    "\n",
    "        start_time = timeit.default_timer() \n",
    "        true_count = count(G,Gstat,query_type,k)\n",
    "        baseline_time = timeit.default_timer() - start_time\n",
    "\n",
    "        print(\"computing ladder\")\n",
    "        start_time = timeit.default_timer(); \n",
    "        ladders = edgedp_ladder_function(G,Gstat,query_type,k)\n",
    "        ladder_compute_time = timeit.default_timer() - start_time\n",
    "        print(\"ladder compute time: \", ladder_compute_time)\n",
    "\n",
    "        query_errors = []\n",
    "        query_stds = []\n",
    "        \n",
    "        for algoKey in range(len(algos)):\n",
    "            algo = algos[algoKey]\n",
    "            print(algo)\n",
    "            \n",
    "            algo_errors = []\n",
    "            algo_stds = []\n",
    "            for epsilon in epsList:\n",
    "                errors = []\n",
    "#                 time = []\n",
    "                \n",
    "                for i in range(repeats):\n",
    "                    noisy= 0.0\n",
    "#                     start_time = timeit.default_timer(); \n",
    "                    if algo == \"edgedp_ladder\":\n",
    "                        noisy = edgedp_ladder_mechanism_noise_sample(G, Gstat, query_type, k, epsilon, ladders, true_count)\n",
    "                    elif algo == \"edgedp_laplace\":\n",
    "                        noisy = edgedp_laplace_mechanism(G, Gstat, query_type, k, epsilon, true_count)\n",
    "                    else:\n",
    "                        if (query_type ==\"kstar\"):\n",
    "                            noisy = edgedp_smooth_sensitivity_mechanism_non_ladder(G, Gstat, query_type, k, epsilon)\n",
    "                        else:\n",
    "                            noisy = edgedp_smooth_sensitivity_mechanism(G, Gstat, query_type, k, epsilon, ladders,\n",
    "                                                                        true_count)\n",
    "                            \n",
    "######### to get time measurements, uncomment the following lines and also the 2 lines containing 'time' above ###################\n",
    "\n",
    "#                     itr_time_end = timeit.default_timer()\n",
    "#                     itr_time = itr_time_end - start_time\n",
    "\n",
    "#                     if(algo == \"edgedp_ladder\"):\n",
    "#                         total_runtime = baseline_time + ladder_compute_time + itr_time\n",
    "#                     elif(algo == \"edgedp_laplace\"):\n",
    "#                         total_runtime = baseline_time + itr_time\n",
    "#                     elif(algo == \"edgedp_smooth\"):\n",
    "#                         if(query_type == \"kstar\"):\n",
    "#                             total_runtime = itr_time\n",
    "#                         else:\n",
    "#                             total_runtime = baseline_time + ladder_compute_time + itr_time\n",
    "#                     time.append(total_runtime)\n",
    "\n",
    "                    relative_error = abs(noisy-true_count)/true_count\n",
    "                    errors.append( relative_error )\n",
    "                    \n",
    "                algo_errors.append(np.mean(errors))\n",
    "                algo_stds.append(np.std(errors))\n",
    "            \n",
    "            query_errors.append(algo_errors)\n",
    "            query_stds.append(algo_stds)\n",
    "\n",
    "        all_errors.append(query_errors)\n",
    "        all_stds.append(query_stds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## plots #########\n",
    "# plot errors and standard deviation\n",
    "\n",
    "params = {'edgedp_laplace':['x','red'], 'edgedp_smooth': ['o','green'],'edgedp_ladder':['>','orange'],}\n",
    "\n",
    "query_error_key = 0 # triangle 0 , kstar 1, kclique 2, ktriangle 3 to plot the error for this specific query\n",
    "errors_to_plot = all_errors[query_error_key]\n",
    "stds_to_plot = all_stds[query_error_key] \n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(3):\n",
    "    algo = algos[i]\n",
    "    err = errors_to_plot[i]\n",
    "    st_dev = stds_to_plot[i]\n",
    "    plt.errorbar(x=epsilon_list, y=err, yerr=st_dev,label=algo,c=params[algo][1],marker=params[algo][0])\n",
    "plt.legend(bbox_to_anchor=(1.1, 1))\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Error')\n",
    "plt.ylim([0,2.5])\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
