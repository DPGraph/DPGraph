{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import collections \n",
    "import numpy as np\n",
    "from scipy.stats import cauchy\n",
    "from sklearn.isotonic import IsotonicRegression  \n",
    "from sklearn.linear_model import LinearRegression \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "def getSortedDegSeq(G):\n",
    "    degSeq = sorted([d for n, d in G.degree()], reverse=False) #small to large degrees\n",
    "    return degSeq\n",
    "\n",
    "def getDegHis(G,maxDeg):\n",
    "    degSeq = getSortedDegSeq(G)\n",
    "    degreeCount = collections.Counter(degSeq)\n",
    "    degHis = np.zeros(maxDeg+1)\n",
    "    for deg in degreeCount:\n",
    "        degHis[deg]=degreeCount[deg]    \n",
    "    return degHis\n",
    "\n",
    "def degSeqToDegHis(degSeq, maxDeg):\n",
    "    #assume deg sequence could be non-integer and be bigger than maxDegree\n",
    "    degHis = np.zeros(maxDeg+1)\n",
    "    for deg in degSeq:\n",
    "        #print(deg)\n",
    "        deg = int(round(deg))\n",
    "        if deg <= maxDeg:\n",
    "            degHis[deg]= degHis[deg]+1\n",
    "    return degHis\n",
    "    \n",
    "    \n",
    "def pdfToCdf(pdf):\n",
    "    cdf = np.zeros(len(pdf))\n",
    "    cdf[0] = pdf[0]\n",
    "    for i in range(1,len(pdf)):\n",
    "         cdf[i] = cdf[i-1] + pdf[i]            \n",
    "    return cdf\n",
    "\n",
    "def cdfToPdf(cdf):\n",
    "    pdf = np.zeros(len(cdf))\n",
    "    pdf[0] = cdf[0]\n",
    "    for i in range(1,len(pdf)):\n",
    "         pdf[i] = cdf[i] - cdf[i-1]            \n",
    "    return pdf\n",
    "    \n",
    "\n",
    "def difDegHis_L1(his1,his2):\n",
    "    #assume the same length\n",
    "    return sum(abs(his1 - his2))\n",
    "\n",
    "def difDegHis_L2(his1,his2):\n",
    "    return sum(np.square(his1-his2))\n",
    "\n",
    "\n",
    "\n",
    "def plotHis(trueHis,noisyHis):\n",
    "    plt.plot(trueHis,'-g', label='trueHis')\n",
    "    plt.plot(noisyHis,'--r', label='noisyHis')\n",
    "    plt.legend();\n",
    "    plt.xscale('log')\n",
    "\n",
    "    \n",
    "def plotCum(trueHis,noisyHis):\n",
    "    plt.plot(pdfToCdf(trueHis), '3b', label='trueCum')\n",
    "    plt.plot(pdfToCdf(noisyHis), '2y', label='noisyCum')\n",
    "    plt.legend();\n",
    "    plt.xscale('log')\n",
    "\n",
    "    \n",
    "#DP basic functions\n",
    "def lap(trueCounts, sens, epsilon):\n",
    "    scale = 1.0* sens/epsilon\n",
    "    noisyCounts = trueCounts + np.random.laplace(0.0, scale, len(trueCounts))\n",
    "    return noisyCounts\n",
    "\n",
    "def postprocessCdf(noisyCdf, totalCount):\n",
    "    #apply isotonic regression\n",
    "    ir = IsotonicRegression(y_min=0, y_max=totalCount, increasing=True)\n",
    "    cdf= ir.fit_transform(X=range(len(noisyCdf)),y=noisyCdf)   \n",
    "    return cdf\n",
    "\n",
    "def postprocessPdf(noisyPdf, nodesNum):\n",
    "    cdf = pdfToCdf(noisyPdf)\n",
    "    cdf = postprocessCdf(cdf, nodesNum)\n",
    "    pdf = cdfToPdf(cdf)\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def extendHis(his,maxDeg):\n",
    "    #his has a shortern length \n",
    "    if (maxDeg+1) > len(his):\n",
    "        hisExtended = np.zeros(maxDeg + 1)\n",
    "        hisExtended[0:len(his)] = his\n",
    "        return hisExtended\n",
    "    else:\n",
    "        return his\n",
    "\n",
    "    \n",
    "def sampleProbList(probList):\n",
    "    #print(probList)\n",
    "    normalizedProbList = probList/sum(probList)\n",
    "    #print(normalizedProbList)\n",
    "    r = np.random.uniform(0,1,1)\n",
    "    s = 0 \n",
    "    for i in range(len(probList)):\n",
    "        s += normalizedProbList[i]\n",
    "        if s >= r:\n",
    "            return i\n",
    "    return len(probList)-1\n",
    "\n",
    "\n",
    "#graph transformation/clean up for subgraph counting aglo (e.g. ladder function) \n",
    "#this remap the node id, such that node id starts from 0 and increments to the total number of nodes \n",
    "def translate(datafile, newDatafile):\n",
    "    nodeMap = dict()\n",
    "    \n",
    "    fin = open(datafile, \"r\")\n",
    "    fout = open(newDatafile, \"w\")\n",
    "    for ij in fin:\n",
    "        i,j = ij.split()\n",
    "        #i = int(i)\n",
    "        #j = int(j)\n",
    "        if i not in nodeMap:\n",
    "            nodeMap[i] = len(nodeMap)\n",
    "        if j not in nodeMap:\n",
    "            nodeMap[j] = len(nodeMap)\n",
    "        \n",
    "        i_map = nodeMap[i]\n",
    "        j_map = nodeMap[j]\n",
    "        if i_map < j_map:\n",
    "            fout.write(str(i_map)+\" \"+str(j_map)+\"\\n\")\n",
    "        else:\n",
    "            fout.write(str(j_map)+\" \"+str(i_map)+\"\\n\")\n",
    "\n",
    "    fout.close()\n",
    "    fin.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge DP algorithms for degree distribution\n",
    "\n",
    "#Hay et al. ICDM'09 (baseline)\n",
    "def edgeDP_degHis_Lap(G, maxDeg, epsilon):\n",
    "    degHis = getDegHis(G, maxDeg)\n",
    "    sens = 4.0\n",
    "    noisyDegHis = lap(degHis, sens, epsilon)\n",
    "    noisyDegHis = postprocessPdf(noisyDegHis, len(G.nodes()))\n",
    "    return noisyDegHis\n",
    "\n",
    "\n",
    "#Hay et al. ICDM'09, Proserpio et al. WOSN'12 (wPINQ)\n",
    "def edgeDP_degSeq_Lap(G, maxDeg, epsilon):\n",
    "    degSeq = np.array(getSortedDegSeq(G))\n",
    "    sens = 2.0\n",
    "    #print(degSeq)\n",
    "    noisyDegSeq = lap(degSeq, sens,epsilon)\n",
    "    noisyDegSeq = postprocessCdf(noisyDegSeq, maxDeg)\n",
    "    #print(noisyDegSeq)\n",
    "    noisyDegHis = degSeqToDegHis(noisyDegSeq, maxDeg)\n",
    "    return noisyDegHis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node DP algorithms for degree distribution\n",
    "################\n",
    "\n",
    "#Day et al. SIGMOD'16 \n",
    "#Algo 1 (projection by edge-addition, variant: output degSeq instead of graph), part of Algo 4\n",
    "def edgeAddition_DegList(G, theta):    \n",
    "    #Edge addition algorithm from empty graph till no edges can be added keep degree bounded by theta\n",
    "    nodesNum = len(G.nodes())\n",
    "    nodesList = list(G.nodes()) #the node ids are not strictly from 0 to |nodesNum|-1\n",
    "    invNodesList = {}\n",
    "    for id in range(nodesNum):\n",
    "        v = nodesList[id]\n",
    "        invNodesList[v]=id\n",
    "    \n",
    "    nodesIndices = np.random.permutation(nodesNum)\n",
    "    degListGt = np.zeros(nodesNum)\n",
    "    \n",
    "    for vid in nodesIndices:\n",
    "        v = nodesList[vid]\n",
    "        for u in G.neighbors(v):\n",
    "            uid = invNodesList[u]\n",
    "            if uid<vid and degListGt[uid]<theta and degListGt[vid]<theta:\n",
    "                degListGt[uid] = degListGt[uid]+1\n",
    "                degListGt[vid] = degListGt[vid]+1\n",
    "                \n",
    "    degListGt=sorted(degListGt, reverse=False) #small to large degrees\n",
    "    #print(degListGt)\n",
    "    \n",
    "    #degSeq = getSortedDegSeq(G)\n",
    "    #diff = np.array(degSeq) - np.array(degListGt)\n",
    "    #print(\"difference in deg seq after edge addition\", sum(diff))\n",
    "    \n",
    "    return degListGt\n",
    "\n",
    "#Day et al. SIGMOD'16 \n",
    "#Part of Algo 4 (select an optimal theta) \n",
    "def learnTheta(G, maxDeg, epsilon_theta, epsilon_deg, thetaList):\n",
    "    probList = []\n",
    "    maxTheta = max(thetaList)\n",
    "    sensitivity = 6.0 * maxTheta+4\n",
    "    \n",
    "    for theta in thetaList:\n",
    "        degListGt = edgeAddition_DegList(G,theta)\n",
    "        nodeNumTheta = len([deg for deg in degListGt if deg >theta])\n",
    "        score = -2.0 * nodeNumTheta - np.sqrt(theta) * (theta+1)/epsilon_deg\n",
    "        prob = np.exp(epsilon_theta * score /(2.0 * sensitivity))\n",
    "        probList.append(prob)\n",
    "        \n",
    "    theta = thetaList[sampleProbList(probList)]\n",
    "    return theta\n",
    "\n",
    "#Day et al. SIGMOD'16 \n",
    "#Part of Algo 2 (select an optimal theta and partition) \n",
    "def learnThetaPartition(G, maxDeg, epsilon_theta, epsilon_deg, thetaList, partitionList):\n",
    "    probList = []\n",
    "    maxTheta = max(thetaList)\n",
    "    sensitivity = 6.0 * maxTheta+4\n",
    "    \n",
    "    his = getDegHis(G,maxDeg)\n",
    "    for theta in thetaList:\n",
    "        degListGt = edgeAddition_DegList(G,theta)\n",
    "        nodeNumTheta = len([deg for deg in degListGt if deg >theta])\n",
    "        lproj = 2.0 * nodeNumTheta\n",
    "        for partition in partitionList:            \n",
    "            lhist = 0 \n",
    "            for i in range(len(partition)-1):\n",
    "                start = partition[i]\n",
    "                end = partition[i+1]\n",
    "                ave = sum(his[start:end])/(end-start)\n",
    "                diff = sum(abs(his[start:end] - ave))\n",
    "                lhist = lhist + diff + (2.0*theta+1)/epsilon_deg\n",
    "        score = -1.0 * (lhist + lproj)\n",
    "        prob = np.exp(epsilon_theta * score /(2.0 * sensitivity))\n",
    "        probList.append(prob)\n",
    "        \n",
    "    sampleIndex = sampleProbList(probList)\n",
    "    thetaIndex = int(sampleIndex / len(partitionList))\n",
    "    partitionIndex = sampleIndex % len(partitionList)\n",
    "    theta= thetaList[thetaIndex]\n",
    "    partition = partitionList[partitionIndex]\n",
    "    return theta,partition\n",
    "\n",
    "\n",
    "#Day et al. SIGMOD'16 \n",
    "#Algo 3(extract histogram from cumulative histogram), part of Algo 4\n",
    "def extractHist(cumHist): #cumHist is noisy cumulative histogram\n",
    "    theta = len(cumHist)-1\n",
    "    hist = np.zeros(len(cumHist))\n",
    "    hc=list(cumHist)\n",
    "    hc.append(cumHist[theta])\n",
    "    hc[0] = 0\n",
    "    i = 1\n",
    "    if hc[1] <0:\n",
    "        hc[1] = 0\n",
    "    \n",
    "    while i <= theta:\n",
    "        if hc[i] <= hc[i+1]:\n",
    "            hist[i] = max(hc[i] - hc[i-1],0)\n",
    "            #print('a:', i, hist[i])\n",
    "            i = i+1\n",
    "        else:\n",
    "            iold = i\n",
    "            jlist = list(reversed(range(i,theta+2)))\n",
    "            #print(jlist)\n",
    "            for j in jlist:\n",
    "                if hc[j-1] < hc[i]:\n",
    "                    j = min(j,theta)\n",
    "                    for k in range(i,j+1):\n",
    "                        hist[k] = max(0,(hc[j]-hc[i-1])/(j-i+1))\n",
    "                        #print('b:', k, hist[k])\n",
    "                    i= j+1\n",
    "                    break \n",
    "            if i == iold:\n",
    "                #print(\"i does not change\", i, cumHist[i:theta])\n",
    "                break\n",
    "    #print(pdfToCdf(hist))\n",
    "    return hist\n",
    "    \n",
    "\n",
    "#Day et al. SIGMOD'16 \n",
    "#Algo 5 (postprocess for tail destribution), part of Algo 4\n",
    "#The last bin has a high count which contains the number of nodes with degree \"at least\" theta in G. \n",
    "def postTail(hist, theta):\n",
    "    budget = hist[theta]\n",
    "    #print(\"budget\", budget)    \n",
    "    start = int(round(theta/2))\n",
    "    cbar = 2.0/theta * sum(hist[start:theta])\n",
    "    \n",
    "    X = np.array([[x] for x in range(start,theta)])\n",
    "    #print(X)\n",
    "    y = hist[start:theta]\n",
    "    #print(y)\n",
    "    reg = LinearRegression().fit(X,y)\n",
    "    m = reg.coef_\n",
    "    b = reg.intercept_ \n",
    "    #print(m,b)\n",
    "    \n",
    "    for k in range(theta, len(hist)):\n",
    "        if m<0:\n",
    "            #hist[k] = b + m * k #This step has an issue when theta is small, then b is small, and counts become negative\n",
    "            hist[k] = max(b + m * k,0) \n",
    "        else:\n",
    "            hist[k] = cbar\n",
    "        budget = budget - hist[k]\n",
    "        if budget <0:\n",
    "            break\n",
    "    return hist \n",
    "\n",
    "\n",
    "#Raskhodnikova & Smith, Arxiv'15\n",
    "def flowgraph(G, theta):\n",
    "    #https://www.cvxpy.org/examples/basic/quadratic_program.html\n",
    "    #Raskhodnikova & Smith, Arxiv'15\n",
    "    #Note: this algo is slow, take more than 1 min for nodeNum=200\n",
    "    #May switch to a diffferent solver: https://pypi.org/project/qpsolvers/  (as @ is no longer recognized by new version of python)\n",
    "\n",
    "    nodesNum = len(G.nodes()) \n",
    "    edgesNum = len(G.edges())\n",
    "    print(nodesNum,edgesNum)\n",
    "\n",
    "    nn = nodesNum * 2\n",
    "    ne = edgesNum * 2\n",
    "    n = nn + ne\n",
    "\n",
    "    P = np.zeros([n,n])\n",
    "    P[:(nn),:(nn)] = np.identity(nn)\n",
    "\n",
    "    q = np.zeros(n)\n",
    "    q[:(nn)] = -2.0* theta\n",
    "\n",
    "    T = np.identity(n)\n",
    "    h = np.zeros(n)+1\n",
    "    h[:nn] = theta \n",
    "\n",
    "    #print(T,h)\n",
    "\n",
    "    A = np.zeros([nn,n])\n",
    "    edgeCount = nn\n",
    "    for i in range(nodesNum):\n",
    "        A[i,i] = 1 \n",
    "        A[nodesNum+i,nodesNum+i] = 1\n",
    "        neighborSize = len([k for k in G.neighbors(i)])\n",
    "        for j in range(neighborSize):\n",
    "            A[i,(edgeCount+j)] = -1\n",
    "            A[nodesNum+i,(edgeCount+j)] = -1\n",
    "        edgeCount = edgeCount + neighborSize\n",
    "    #print(A)\n",
    "\n",
    "    x = cp.Variable(n)\n",
    "    prob = cp.Problem(cp.Minimize(cp.quad_form(x,P)+ q.T @ x), [T @x <=h, x>=0, A@x == 0 ])\n",
    "    prob.solve()\n",
    "    #print(\"\\nThe optimal value is\", prob.value)\n",
    "    #print(\"A solution x is\")\n",
    "\n",
    "    degList = []\n",
    "    for i in range(nodesNum):\n",
    "        degList.append(int(x.value[i,0].round()))\n",
    "    degSeq = sorted(degList,reverse=False)\n",
    "    #print(degSeq)\n",
    "    return degSeq\n",
    "\n",
    "#Raskhodnikova & Smith, Arxiv'15\n",
    "def flowgraphApprox(G,theta):\n",
    "    #TODO: more efficient approximation algorithmm, but sensitivity will increase\n",
    "    degSeq = []\n",
    "    return degSeq\n",
    "\n",
    "################\n",
    "#Naive laplace mechanism with postprocessing\n",
    "def nodeDP_degHis_Lap(G, maxDeg, epsilon):\n",
    "    degHis = getDegHis(G,maxDeg)\n",
    "    sens = 2.0 * (maxDeg + 1)\n",
    "    noisyDegHis = lap(degHis, sens, epsilon)\n",
    "    noisyDegHis = postprocessPdf(noisyDegHis, len(G.nodes()))\n",
    "    return noisyDegHis\n",
    "\n",
    "#Adapting Hay et al. ICDM'09, Proserpio et al. WOSN'12 (wPINQ)\n",
    "def nodeDP_degSeq_Lap(G, maxDeg, epsilon):\n",
    "    degSeq = np.array(getSortedDegSeq(G))\n",
    "    sens = 1.0* (maxDeg + 1)\n",
    "    #print(degSeq)\n",
    "    noisyDegSeq = lap(degSeq, sens,epsilon)\n",
    "    noisyDegSeq = postprocessCdf(noisyDegSeq, len(G.nodes()))\n",
    "    #print(noisyDegSeq)\n",
    "    noisyDegHis = degSeqToDegHis(noisyDegSeq, maxDeg)\n",
    "    #print(noisyDegHis)\n",
    "    return noisyDegHis\n",
    "\n",
    "#Shiva et al. TCC'13\n",
    "def nodeDP_nodeTrun_Smooth(G, maxDeg, epsilon, theta):\n",
    "    epsilon_deg = epsilon \n",
    "    \n",
    "    #node truncation: remove nodes with degree > theta \n",
    "    Gt = G.copy()\n",
    "    nodesTrun = [n for n,d in Gt.degree() if d > theta]\n",
    "    Gt.remove_nodes_from(nodesTrun)\n",
    "\n",
    "    #smooth bound: (Prop 6.1, Algo 3)\n",
    "    nodesNum = len(G.nodes())\n",
    "    beta = epsilon/(np.sqrt(2.0)*(theta+1))   ## epsilon * np.log(nodesNum/theta)\n",
    "    r = np.log(1.0*nodesNum/beta)\n",
    "    l = len([n for n,d in Gt.degree() if (d >= theta-r and d<=theta+r)])\n",
    "    smoothSens = l+1.0/beta + 1\n",
    "    #print(beta, r, l,smoothSens)\n",
    "    \n",
    "    #add cauchy noise with epsilon_deg\n",
    "    scale = 2*np.sqrt(2.0)*theta/epsilon_deg*smoothSens\n",
    "    trueHisGt = getDegHis(Gt, theta)\n",
    "    noisyHisGt = trueHisGt + cauchy.rvs(0,scale=smoothSens,size=len(trueHisGt))\n",
    "    noisyHisG = extendHis(noisyHisGt, maxDeg)\n",
    "    \n",
    "    #postprocess (TCC DOES NOT HAVE THIS STEP)\n",
    "    noisyHisG = postprocessPdf(noisyHisG, len(G.nodes()))\n",
    "    \n",
    "    return noisyHisG\n",
    "\n",
    "\n",
    "#Raskhodnikova & Smith, Arxiv'15\n",
    "def nodeDP_flowgraph_degSeq_Lap(G, maxDeg, epsilon, theta):\n",
    "    epsilon_deg = epsilon \n",
    "    \n",
    "    #TODO: add generalized exponential mechanism for selecting threshold theta\n",
    "    \n",
    "    \n",
    "    #Flowgraph algorithm to obtain a degree sequence with max degree is bounded by theta\n",
    "    degSeq = flowgraph(G,theta) #getSortedDegSeq(G) #TODO: replace this line with flowgraph algorithm \n",
    "    \n",
    "    #Convert degSeq to degHis and add noise (this step can be improved by learn noisy seq first)\n",
    "    sens = 6.0 *theta  #Algo 1: this requires an exact solver for the flowgraph; if an approximation algorithm is used, then the sensitivity needs go up.\n",
    "    degHis = degSeqToDegHis(degSeq, theta)\n",
    "    noisyDegHis = lap(degHis, sens, epsilon_deg)\n",
    "    \n",
    "    noisyHisG = extendHis(noisyDegHis, maxDeg)\n",
    "    \n",
    "    #postprocess (THE PAPER DOES NOT HAVE THIS STEP)\n",
    "    noisyHisG = postprocessPdf(noisyHisG, len(G.nodes()))\n",
    "    \n",
    "    return noisyHisG\n",
    "\n",
    "\n",
    "#Day et al. SIGMOD'16\n",
    "def nodeDP_edgeAdd_degHisPart_Lap(G, maxDeg, epsilon, thetaList, paritionList):\n",
    "    ##TODO: incomplete (exponential mechanism to get a partition first, and then apply Lap)\n",
    "    return 0\n",
    "\n",
    "\n",
    "#Day et al. SIGMOD'16\n",
    "#variant of Algo 4 (\\theta-constrained)\n",
    "def nodeDP_edgeAdd_degCum_Lap_variant(G, maxDeg, epsilon, thetaList):\n",
    "    theta = thetaList[0]\n",
    "    epsilon_deg = epsilon\n",
    "    \n",
    "    #Learning theta \n",
    "    if len(thetaList) >1: #many choices \n",
    "        epsilon_theta = epsilon * 0.1\n",
    "        epsilon_deg = epsilon-epsilon_theta\n",
    "        theta = learnTheta(G, maxDeg, epsilon_theta, epsilon_deg, thetaList)\n",
    "        #print(\"sampled theta\", theta)\n",
    "\n",
    "    #Edge addition algorithm from empty graph till no edges can be added keep degree bounded by theta\n",
    "    degListGt = edgeAddition_DegList(G,theta)\n",
    "    #print(degListGt)\n",
    "    \n",
    "    #cumulative historm + lap noise\n",
    "    degHis = degSeqToDegHis(degListGt, theta)\n",
    "    degCum = pdfToCdf(degHis)\n",
    "    #print(degCum[0:30]) \n",
    "    sens = theta + 1 \n",
    "    noisyDegCum = lap(degCum, sens, epsilon_deg)\n",
    "    \n",
    "    #print(\"noisyDegCum\", noisyDegCum[0:30])\n",
    "    noisyDegCum = postprocessCdf(noisyDegCum, len(G.nodes())) #Not Algo 3\n",
    "    #print(\"noisyDegCum - monotonicity\", noisyDegCum[0:30])\n",
    "    noisyDegHis = cdfToPdf(noisyDegCum)\n",
    "    noisyDegHis = extendHis(noisyDegHis,maxDeg)\n",
    "    #print(\"noisyDegHis - extend lengh\", noisyDegHis)\n",
    "    noisyDegHis = postTail(noisyDegHis, theta)\n",
    "    #print(\"noisyDegHis - post tail\", noisyDegHis)\n",
    "    \n",
    "    return noisyDegHis\n",
    "        \n",
    "\n",
    "#Day et al. SIGMOD'16\n",
    "#Algo 4 (\\theta-cumulative)\n",
    "def nodeDP_edgeAdd_degCum_Lap(G, maxDeg, epsilon, thetaList):\n",
    "    theta = thetaList[0]\n",
    "    epsilon_deg = epsilon\n",
    "    \n",
    "    #Learning theta \n",
    "    if len(thetaList) >1: #many choices \n",
    "        epsilon_theta = epsilon * 0.1\n",
    "        epsilon_deg = epsilon-epsilon_theta\n",
    "        theta = learnTheta(G, maxDeg, epsilon_theta, epsilon_deg, thetaList)\n",
    "        #print(\"sampled theta\", theta)\n",
    "\n",
    "    #Edge addition algorithm from empty graph till no edges can be added keep degree bounded by theta\n",
    "    degListGt = edgeAddition_DegList(G,theta)\n",
    "    #print(degListGt)\n",
    "    \n",
    "    #cumulative historm + lap noise\n",
    "    degHis = degSeqToDegHis(degListGt, theta)\n",
    "    degCum = pdfToCdf(degHis)\n",
    "    #print(degCum[0:30]) \n",
    "    sens = theta + 1 \n",
    "    noisyDegCum = lap(degCum, sens, epsilon_deg)\n",
    "    \n",
    "    #print(\"noisyDegCum\", noisyDegCum[0:30])\n",
    "    noisyDegHis = extractHist(noisyDegCum) #Algo 3\n",
    "    #print(\"noisyDegCum - monotonicity\", noisyDegCum[0:30])\n",
    "    \n",
    "    noisyDegHis = extendHis(noisyDegHis,maxDeg)\n",
    "    #print(\"noisyCumDegHis - extend lengh\", noisyDegHis[0:30])\n",
    "    noisyDegHis = postTail(noisyDegHis, theta)\n",
    "    #print(\"noisyDegHis - post tail\", noisyDegHis[0:30])\n",
    "    \n",
    "    return noisyDegHis\n",
    "\n",
    "\n",
    "#Day et al. SIGMOD'16\n",
    "#Algo 2 (\\theta,\\Omega-cumulative)\n",
    "def nodeDP_edgeAdd_degHisPart_Lap(G, maxDeg, epsilon, thetaList, rList):\n",
    "    theta = thetaList[0]\n",
    "    epsilon_deg = epsilon\n",
    "\n",
    "    #Create a set of partitions based on rList\n",
    "    partitionList = []\n",
    "    for r in rList:\n",
    "        partition = [0]\n",
    "        i = 0 \n",
    "        k = int(round(np.power(r, i)))\n",
    "        while k < maxDeg:\n",
    "            if k > partition[len(partition)-1]:\n",
    "                partition.append(k)\n",
    "            i = i+1\n",
    "            k = int(round(np.power(r, i)))\n",
    "        partition.append(maxDeg) #we also add the maxDeg for the easy aggregation\n",
    "        partitionList.append(partition)\n",
    "    \n",
    "    partition = partitionList[0]\n",
    "    #Learning theta and partition\n",
    "    if len(thetaList) >1 or len(partitionList)>1: #many choices \n",
    "        epsilon_theta = epsilon * 0.1\n",
    "        epsilon_deg = epsilon-epsilon_theta\n",
    "        (theta, partition) = learnThetaPartition(G, maxDeg, epsilon_theta, epsilon_deg, thetaList, partitionList)\n",
    "        #print(\"sampled theta\", theta, \"sampled partition\", partition)\n",
    "\n",
    "    #Edge addition algorithm from empty graph till no edges can be added keep degree bounded by theta\n",
    "    degListGt = edgeAddition_DegList(G,theta)\n",
    "    #print(degListGt)\n",
    "    \n",
    "    # historm + lap noise\n",
    "    degHis = degSeqToDegHis(degListGt, theta)\n",
    "    noisyDegHis = np.zeros(len(degHis))\n",
    "    sens = 1 \n",
    "    for i in range(len(partition)-1):\n",
    "        start = partition[i]\n",
    "        end = partition[i+1]\n",
    "        if end >= (theta+1):\n",
    "            end = min(end,theta+1)\n",
    "        noisyAve = (sum(degHis[start:end]) + lap([0],sens,epsilon_deg)[0])/(end-start)\n",
    "        for j in range(start,end):\n",
    "            noisyDegHis[j] = noisyAve\n",
    "        if end >= (theta+1):\n",
    "            break \n",
    "                \n",
    "    noisyDegHis = extendHis(noisyDegHis,maxDeg)\n",
    "    #print(\"noisyCumDegHis - extend lengh\", noisyDegHis[90:110])\n",
    "    noisyDegHis = postTail(noisyDegHis, theta)\n",
    "    #print(\"noisyDegHis - post tail\", noisyDegHis[90:110])\n",
    "    \n",
    "    return noisyDegHis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HepPh.txt\n",
      "[   0. 1492. 1802. ...    0.    0.    0.]\n",
      "1 89208 12008\n"
     ]
    }
   ],
   "source": [
    "#Caller \n",
    "\n",
    "dataDir =\"Datasets/\"\n",
    "dataNames = [\"HepPh.txt\",\"toydata.txt\", \"facebook_combined.txt\", \"wiki-Vote.txt\", \n",
    "             \"email-Enron.txt\",  \"cit-HepTh.txt\", \"com-dblp.ungraph.txt\"]\n",
    "dataKey = 0\n",
    "dataName = dataNames[dataKey]\n",
    "print(dataName)\n",
    "\n",
    "datafile = dataDir+dataName #\"facebook_combined.txt\"\n",
    "G=nx.read_edgelist(datafile, nodetype=int)\n",
    "#G = nx.fast_gnp_random_graph(20,0.2)\n",
    "\n",
    "nodesNum = len(G.nodes()) #assume this is given\n",
    "maxDeg = nodesNum -1  #assume this is given\n",
    "\n",
    "trueHis = getDegHis(G,maxDeg)\n",
    "print(trueHis)\n",
    "\n",
    "nodesList = list(G.nodes)\n",
    "print(min(nodesList),max(nodesList),len(nodesList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing of algorithms for degree distribution\n",
    "epsilon = 10.0\n",
    "maxTheta = min(nodesNum-1,200)\n",
    "#noisyDegHis = nodeDP_nodeTrun_Smooth(G,maxDeg,epsilon, maxTheta)\n",
    "###noisyDegHis = nodeDP_flowgraph_degSeq_Lap(G,maxDeg,epsilon, maxTheta) #works for small graph\n",
    "#thetaCandidates = list(range(maxTheta))\n",
    "thetaCandidates = [20,40,60,80,100,120,140,160,180,200]\n",
    "#thetaCandidates = [100]#[nodesNum-1]\n",
    "rCandidates = [1.2,1.5] #r determines the partition (g_i = {k:r^{i-1}<= k < r^i})\n",
    "#noisyDegHis = nodeDP_edgeAdd_degHisPart_Lap(G, maxDeg, epsilon, thetaCandidates, rCandidates) \n",
    "#noisyDegHis = nodeDP_edgeAdd_degCum_Lap(G,maxDeg,epsilon,thetaCandidates)\n",
    "noisyDegHis = nodeDP_edgeAdd_degCum_Lap_variant(G,maxDeg,epsilon,thetaCandidates)\n",
    "\n",
    "#print(\"trueHist0-29\", trueHis[0:30])\n",
    "#print(\"noisyHist0-29\", noisyDegHis[0:30])\n",
    "plotHis(trueHis/nodesNum,noisyDegHis/nodesNum)\n",
    "print(difDegHis_L1(trueHis/nodesNum, noisyDegHis/nodesNum))\n",
    "print(difDegHis_L1(trueHis/nodesNum, (np.zeros(maxDeg+1))/nodesNum))\n",
    "print(difDegHis_L1(trueHis, noisyDegHis))\n",
    "print(difDegHis_L1(trueHis, (np.zeros(maxDeg+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf1=1-pdfToCdf(trueHis)\n",
    "cdf2=1-pdfToCdf(noisyDegHis)\n",
    "\n",
    "plotCum(cdf1,cdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Evaluation of algorithms for degree distribution\n",
    "\n",
    "algoNames = [\"edgeDP_degHis_Lap\", \n",
    "             \"edgeDP_degSeq_Lap\", \n",
    "             \"nodeDP_degHis_Lap\", \n",
    "             \"nodeDP_degSeq_Lap\", \n",
    "             \"nodeDP_nodeTrun_Smooth\", \n",
    "             \"nodeDP_edgeAdd_degHisPart_Lap\", \n",
    "             \"nodeDP_edgeAdd_degCum_Lap\",\n",
    "             \"nodeDP_edgeAdd_degCum_Lap_variant\",\n",
    "             \"nodeDP_flowgraph_degSeq_Lap\"]\n",
    "algoKey = 6\n",
    "algo = algoNames[algoKey]\n",
    "print(algo)\n",
    "\n",
    "#epsList = [0.01,0.02,0.05,0.1,0.2,0.5,1.0,2.0,5.0,10.0]\n",
    "#epsList = [0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "epsList = [1.0]\n",
    "repeats = 1\n",
    "\n",
    "maxTheta = min(nodesNum-1,200)\n",
    "thetaCandidates = [20,40,60,80,100,120,140,160,180,200]\n",
    "if maxTheta < 200:\n",
    "    thetaCandidates = [i+1 for i in range(maxTheta)]\n",
    "#print(thetaCandidates)\n",
    "\n",
    "for epsilon in epsList:\n",
    "    errors = []\n",
    "    for i in range(repeats):\n",
    "        noisyDegHis = np.zeros(maxDeg+1)\n",
    "        if algo == \"edgeDP_degHis_Lap\":        \n",
    "            noisyDegHis = edgeDP_degHis_Lap(G,maxDeg,epsilon)\n",
    "        elif algo == \"edgeDP_degSeq_Lap\":\n",
    "            noisyDegHis = edgeDP_degSeq_Lap(G,maxDeg,epsilon)\n",
    "        elif algo == \"nodeDP_degHis_Lap\":\n",
    "            noisyDegHis = nodeDP_degHis_Lap(G,maxDeg,epsilon)\n",
    "        elif algo == \"nodeDP_degSeq_Lap\":\n",
    "            noisyDegHis = nodeDP_degSeq_Lap(G,maxDeg,epsilon)\n",
    "        elif algo == \"nodeDP_nodeTrun_Smooth\":\n",
    "            noisyDegHis = nodeDP_nodeTrun_Smooth(G,maxDeg,epsilon,maxTheta)\n",
    "        elif algo == \"nodeDP_edgeAdd_degHisPart_Lap\":\n",
    "            rCandidates = [1.2,1.5,1.8] #r determines the partition (g_i = {k:r^{i-1}<= k < r^i})\n",
    "            noisyDegHis = nodeDP_edgeAdd_degHisPart_Lap(G, maxDeg, epsilon, thetaCandidates, rCandidates) \n",
    "        elif algo == \"nodeDP_edgeAdd_degCum_Lap\":\n",
    "            noisyDegHis = nodeDP_edgeAdd_degCum_Lap(G,maxDeg,epsilon,thetaCandidates)\n",
    "        elif algo == \"nodeDP_edgeAdd_degCum_Lap_variant\":\n",
    "            noisyDegHis = nodeDP_edgeAdd_degCum_Lap_variant(G,maxDeg,epsilon,thetaCandidates)\n",
    "        elif algo == \"nodeDP_flowgraph_degSeq_Lap\":\n",
    "            noisyDegHis = nodeDP_flowgraph_degSeq_Lap(G,maxDeg,epsilon, maxTheta) #works for small graph\n",
    "        else:\n",
    "            print(\"no valid algo\")\n",
    "        noisyPdf = noisyDegHis/nodesNum\n",
    "        #print(maxTheta)\n",
    "        #print(trueHis)\n",
    "        #print(noisyDegHis)\n",
    "        error = difDegHis_L1(trueHis/nodesNum, noisyDegHis/nodesNum)\n",
    "        #print(i, error)\n",
    "        errors.append(error)\n",
    "        #plotHis(trueHis/nodesNum,noisyDegHis/nodesNum)\n",
    "        #plotCum(trueHis/nodesNum,noisyDegHis/nodesNum)\n",
    "                \n",
    "    print(epsilon, np.mean(errors), np.std(errors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####unused code\n",
    "##sparse version (my version, not useful for local sensitivity computation)\n",
    "\n",
    "###full neighbors set (costly to compute and store)\n",
    "start_time = time.time()\n",
    "commonNeighbors = defaultdict(set)\n",
    "for i in range(nodesNum):\n",
    "    #print(set(G[i].keys()))\n",
    "    for j in set(G[i].keys()):\n",
    "        if j>i:\n",
    "            commonN = set(G[i].keys()).intersection(set(G[j].keys()))\n",
    "            #print(i,j, commonN)\n",
    "            commonNeighbors.update({'{},{}'.format(i,j):commonN})\n",
    "\n",
    "#print(commonNeighbors)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class graphStat(object):\n",
    "    #mainly store aggregated statistics of G\n",
    "    \n",
    "    def __init__(self, G):\n",
    "        #take in networkx as an argument\n",
    "    \n",
    "        #degree number \n",
    "        self.nodesNum = len(G.nodes())\n",
    "\n",
    "        #A_ij: the set of common neighbors of i and j \n",
    "        self.A = defaultdict(set)\n",
    "        self.maxA = -1.0\n",
    "\n",
    "        self.initSparseA(G)\n",
    "         \n",
    "    def initSparseA(self, G):\n",
    "        start_time = time.time()\n",
    "        for u,v in G.edges(): #edges in G only store one copy: either (u,v) or (v,u), not both\n",
    "            for p in G[u]:\n",
    "                if p != v:\n",
    "                    self.A['{},{}'.format(min(p,v), max(p,v))].add(u)\n",
    "            for p in G[v]:\n",
    "                if p != u:\n",
    "                    self.A['{},{}'.format(min(p,u),max(p,u))].add(v)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        for commonNeighbors in self.A.values():\n",
    "            self.maxA = max(self.maxA, len(commonNeighbors))\n",
    "        \n",
    "        \n",
    "    def getA(self,i,j):\n",
    "        return self.A['{},{}'.format(i,j)]\n",
    "    \n",
    "    \n",
    "    def geta(self,i,j):\n",
    "        return len(self.getA(i,j))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clique(G,nodesRange,k):\n",
    "    if(len(nodesRange)<k):\n",
    "        return 0\n",
    "    elif k==1:\n",
    "        return len(nodesRange)\n",
    "\n",
    "    count = 0\n",
    "    for i in nodesRange:\n",
    "        count += count_clique(G, set(G[i].keys()).intersection(nodesRange),k-1)\n",
    "    return count/k\n",
    "\n",
    "def count(G, Gstat, queryType, k):\n",
    "    start_time = time.time()\n",
    "    count = 0\n",
    "    if queryType == \"triangle\":\n",
    "        for u,v in G.edges():\n",
    "            count = count + Gstat.geta(min(u,v),max(u,v))\n",
    "        count = count/3 \n",
    "    elif queryType == \"kstar\":\n",
    "        for i in range(Gstat.nodesNum):\n",
    "            d = G.degree[i]\n",
    "            if d >= k:\n",
    "                count = count + comb(d,k)\n",
    "    elif queryType == \"kclique\":\n",
    "        for u,v in G.edges():\n",
    "            count += count_clique(G,Gstat.getA(min(u,v),max(u,v)), k-2)\n",
    "        count /= comb(k,2)\n",
    "    elif queryType == \"ktriangle\":\n",
    "        for u,v in G.edges():\n",
    "            count = count + comb(Gstat.geta(min(u,v),max(u,v)),k)    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Edge-DP \n",
    "def edgeDP_computeGS(G, Gsstat, queryType, k):\n",
    "    nodesNum = Gstat.nodesNum\n",
    "    if queryType == \"triangle\":\n",
    "        return nodesNum-2\n",
    "    elif queryType == \"kstar\":\n",
    "        return 2 * comb(nodesNum-2, k-1)\n",
    "    elif queryType == \"kclique\":\n",
    "        return comb(nodesNum-2,k-2)\n",
    "    elif queryType == \"ktriangle\":\n",
    "        return comb(nodesNum-2,k) + 2*(nodesNum-2)*comb(nodesNum-3,k-1)\n",
    "    else:\n",
    "        print(queryType, \"is unspecified\")\n",
    "        return -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists\n",
      "Datasets/facebook_combined-map.txt\n",
      "88234\n",
      "[ 0. 75. 98. ...  0.  0.  0.]\n",
      "0 4038 4039\n",
      "88234\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "#Caller \n",
    "\n",
    "dataDir =\"Datasets/\"\n",
    "dataNames = [\"HepPh\",\"toydata\", \"facebook_combined\", \"wiki-Vote\", \n",
    "             \"email-Enron\",  \"cit-HepTh\", \"com-dblp.ungraph\"]\n",
    "dataKey = 2\n",
    "dataName = dataNames[dataKey]\n",
    "\n",
    "datafile = dataDir+dataName #\"facebook_combined.txt\"\n",
    "if not os.path.isfile(datafile+\"-map.txt\"):\n",
    "    translate(datafile+\".txt\", datafile+\"-map.txt\")\n",
    "    #convert all nodes id to 0 to nodeNum\n",
    "else:\n",
    "    print(\"file exists\")\n",
    "    \n",
    "datafile = datafile + \"-map.txt\"\n",
    "print(datafile)\n",
    "\n",
    "G=nx.read_edgelist(datafile, nodetype=int)\n",
    "#G = nx.fast_gnp_random_graph(20,0.2)\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "print(len(G.edges))\n",
    "\n",
    "nodesNum = len(G.nodes()) #assume this is given\n",
    "maxDeg = nodesNum -1  #assume this is given\n",
    "\n",
    "trueHis = getDegHis(G,maxDeg)\n",
    "print(trueHis)\n",
    "\n",
    "nodesList = list(G.nodes)\n",
    "print(min(nodesList),max(nodesList),len(nodesList))\n",
    "\n",
    "print(len(G.edges))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 25.199180126190186 seconds ---\n"
     ]
    }
   ],
   "source": [
    "Gstat = graphStat(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.18755507469177246 seconds ---\n",
      "1612010.0\n",
      "--- 0.035372018814086914 seconds ---\n",
      "727318426.0\n",
      "--- 86.82794713973999 seconds ---\n",
      "30004668.0\n",
      "--- 0.6820480823516846 seconds ---\n",
      "228787050.0\n"
     ]
    }
   ],
   "source": [
    "####triangle \n",
    "print(count(G,Gstat,\"triangle\",-1))\n",
    "\n",
    "####k-star, k=3\n",
    "print(count(G,Gstat,\"kstar\",3))\n",
    "\n",
    "####k-clique, k=4 \n",
    "print(count(G,Gstat,\"kclique\",4))\n",
    "\n",
    "####k-triangle, k=2 \n",
    "print(count(G,Gstat,\"ktriangle\",2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDP_computeLS(G, Gstat, queryType, k):\n",
    "    ls = 0.0 \n",
    "    if queryType == \"triangle\":\n",
    "        ls = Gstat.maxA\n",
    "        return ls\n",
    "    elif queryType == \"kstar\":\n",
    "        #TODO: incomplete\n",
    "        return ls\n",
    "    elif queryType == \"kclique\":\n",
    "        #TODO: incomplete\n",
    "        return ls\n",
    "    elif queryType == \"ktriangle\":\n",
    "        #TODO: incomplete\n",
    "        return ls\n",
    "    else:\n",
    "        print(queryType, \"is unspecified\")\n",
    "        return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDP_LadderFunction(G, Gstat, queryType, k):\n",
    "    lsd = []    \n",
    "    if queryType == \"triangle\":\n",
    "        lsd = lsd_triangle(G,Gstat,queryType,k)\n",
    "    elif queryType == \"kstar\":\n",
    "         #TODO: incomplete\n",
    "        return lsd\n",
    "    elif queryType == \"kclique\":\n",
    "         #TODO: incomplete\n",
    "        return lsd\n",
    "    elif queryType == \"ktriangle\":\n",
    "        #TODO: incomplete\n",
    "        return lsd\n",
    "    else:\n",
    "        print(queryType, \"is unspecified\")\n",
    "    return lsd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsd_triangle(G,Gstat,queryType,k):\n",
    "    start_time = time.time()\n",
    "    nodesNum = Gstat.nodesNum\n",
    "    bucket = [-1] * nodesNum #bucket: the common neighbor sizes \n",
    "    for i in range(nodesNum):\n",
    "        for j in range(i+1, nodesNum):\n",
    "            #aij: the number of common neighbors of i and j\n",
    "            aij = Gstat.geta(i,j)\n",
    "            #di = G.degree[i]\n",
    "            #dj = G.degree[j]\n",
    "            #xij = int(G.has_edge(i,j))\n",
    "            #bij: the number of nodes connected to exactly one of i and j\n",
    "            bij = G.degree[i] + G.degree[j] - 2*aij - 2*int(G.has_edge(i,j))\n",
    "            bucket[aij] = max(bucket[aij], bij)  \n",
    "            #if (i==0 and j <10):\n",
    "            #    print(i,j,aij, bucket[aij], di,dj,xij)\n",
    "            \n",
    "    print(\"bucket(0-10):\", bucket[0:10])\n",
    "    \n",
    "    uppers = []\n",
    "    for i in reversed(range(nodesNum)):\n",
    "        if bucket[i] <0:\n",
    "            continue\n",
    "        if (len(uppers)==0) or (i*2+bucket[i] > uppers[-1][0]*2 + uppers[-1][1]):\n",
    "            uppers.append([i, bucket[i]])\n",
    "    #print(\"uppers(0-10):\", uppers[0:10])\n",
    "    \n",
    "    gs = edgeDP_computeGS(G,Gstat,queryType,k)\n",
    "    #print(\"gs: \", gs)\n",
    "    \n",
    "    LSD = []\n",
    "    t = 0\n",
    "    \n",
    "    while 1:\n",
    "        lsd = 0\n",
    "        for p in uppers:\n",
    "            lsd = max(lsd, p[0]+ (t+min(t,p[1])) /2)\n",
    "        t +=1 \n",
    "        if lsd < gs:\n",
    "            LSD.append(lsd)\n",
    "        else:\n",
    "            LSD.append(gs)\n",
    "            print(\"LSD(0-10):\", LSD[0:10])\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            return LSD    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 16 330 347 17 1\n",
      "0 2 9 337 347 10 1\n",
      "0 3 16 330 347 17 1\n",
      "0 4 9 337 347 10 1\n",
      "0 5 12 334 347 13 1\n",
      "0 6 5 341 347 6 1\n",
      "0 7 19 327 347 20 1\n",
      "0 8 7 339 347 8 1\n",
      "0 9 56 290 347 57 1\n",
      "bucket(0-10): [1339, 1590, 1386, 1333, 1077, 1095, 1788, 1079, 1090, 1093]\n",
      "uppers(0-10): [[293, 461], [253, 791], [14, 1807]]\n",
      "gs:  4037\n",
      "LSD(0-10): [293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0]\n",
      "--- 86.31673192977905 seconds ---\n"
     ]
    }
   ],
   "source": [
    "####triangle \n",
    "queryType = \"triangle\"\n",
    "k=-1\n",
    "#print(edgeDP_computeLS(G,Gstat,queryType,k))\n",
    "lsd = edgeDP_LadderFunction(G, Gstat, queryType, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ladder function paper: algorithm 1 \n",
    "def edgeDP_LadderMechanism(G, Gstat, queryType, k, epsilon, repetition):\n",
    "    trueCount = count(G,Gstat,queryType,k)\n",
    "    print(queryType,k, \"true count: \", trueCount)\n",
    "    \n",
    "    #ladders: ladder function evaluated on G\n",
    "    ladders = edgeDP_LadderFunction(G,Gstat,queryType,k)  \n",
    "    #M: length of the ladder function\n",
    "    M = len(ladders)\n",
    "    \n",
    "    ranges = []\n",
    "    weights = [1.0] #the center's weight\n",
    "    \n",
    "    #rungs 1 to M\n",
    "    dst = 0.0 \n",
    "    for t in range(M):\n",
    "        weights.append(2*ladders[t]*np.exp(epsilon/2.0*(-t-1)))\n",
    "        ranges.append(dst)\n",
    "        dst = dst + ladders[t]\n",
    "        \n",
    "    #rung M+1\n",
    "    weights.append(2*ladders[-1]* np.exp(epsilon/2.0*(-M-1))/(1-np.exp(-epsilon/2.0)))\n",
    "        \n",
    "    ####the only part that involves randomness, may store the earlier results for evaluation over multiple runs \n",
    "    \n",
    "    errors = []\n",
    "    for i in range(repetition):\n",
    "        noisyCount = 0\n",
    "        \n",
    "        #run exponential mechanism over the weights\n",
    "        t = int(sampleProbList(weights))\n",
    "\n",
    "        if t==0:\n",
    "            noisyCount = trueCount\n",
    "\n",
    "        elif t<= M:\n",
    "            flag = -1.0\n",
    "            if (np.random.uniform()>0.5):\n",
    "                flag = 1.0\n",
    "            low = ranges[t-1]\n",
    "            delta = np.ceil(np.random.uniform() * (ranges[t] - ranges[t-1]))\n",
    "            noisyCount = flag * delta + trueCount\n",
    "\n",
    "        else:\n",
    "            p = 1.0 - np.exp(-epsilon/2.0)\n",
    "            ext = np.random.geometric(p)\n",
    "            low = dst + ext * ladders[-1]\n",
    "            high = low + ladders[-1]\n",
    "            flag = -1.0\n",
    "            if (np.random.uniform()>0.5):\n",
    "                flag = 1.0\n",
    "            noisyCount = flag * np.random.randint(low, high+1) + trueCount\n",
    "        \n",
    "        errors.append(abs(noisyCount-trueCount)/trueCount)\n",
    "    return errors\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.23247575759887695 seconds ---\n",
      "triangle -1 true count:  1612010.0\n",
      "bucket(0-10): [1339, 1590, 1386, 1333, 1077, 1095, 1788, 1079, 1090, 1093]\n",
      "uppers(0-10): [[293, 461], [253, 791], [14, 1807]]\n",
      "gs:  4037\n",
      "LSD(0-10): [293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0]\n",
      "--- 57.03488898277283 seconds ---\n",
      "9.367187548464339e-05\n"
     ]
    }
   ],
   "source": [
    "queryType = \"triangle\"\n",
    "k=-1\n",
    "epsilon = 0.05\n",
    "repetition = 30\n",
    "errors = edgeDP_LadderMechanism(G, Gstat, queryType, k, epsilon,repetition)\n",
    "print(np.mean(errors), np.std(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.16189217567443848 seconds ---\n",
      "triangle -1 true count:  1612010.0\n",
      "480.48780720418335\n",
      "0.0001575672607490028\n",
      "0.00024371436901756194 0.00026513878905179395\n"
     ]
    }
   ],
   "source": [
    "queryType = \"triangle\"\n",
    "k=-1\n",
    "epsilon = 1.6\n",
    "repetition = 100\n",
    "\n",
    "if 1:\n",
    "    trueCount = count(G,Gstat,queryType,k)\n",
    "    print(queryType,k, \"true count: \", trueCount)\n",
    "    \n",
    "    #ladders: ladder function evaluated on G\n",
    "    ladders = lsd\n",
    "    #M: length of the ladder function\n",
    "    M = len(ladders)\n",
    "    \n",
    "    ranges = []\n",
    "    weights = [1.0] #the center's weight\n",
    "    \n",
    "    #rungs 1 to M\n",
    "    dst = 0.0 \n",
    "    for t in range(M):\n",
    "        weights.append(2*ladders[t]*np.exp(epsilon/2.0*(-t-1)))\n",
    "        ranges.append(dst)\n",
    "        dst = dst + ladders[t]\n",
    "        \n",
    "    #rung M+1\n",
    "    weights.append(2*ladders[-1]* np.exp(epsilon/2.0*(-M-1))/(1-np.exp(-epsilon/2.0)))\n",
    "    \n",
    "    print(sum(weights))\n",
    "    \n",
    "    ####the only part that involves randomness, may store the earlier results for evaluation\n",
    "\n",
    "    errors = []\n",
    "    for i in range(repetition):\n",
    "        noisyCount = 0\n",
    "        \n",
    "        #run exponential mechanism over the weights\n",
    "        t = int(sampleProbList(weights))\n",
    "        \n",
    "        if t==0:\n",
    "            noisyCount = trueCount\n",
    "\n",
    "        elif t<= M:\n",
    "            flag = -1.0\n",
    "            if (np.random.uniform()>0.5):\n",
    "                flag = 1.0\n",
    "            low = ranges[t-1]\n",
    "            delta = low + np.ceil(np.random.uniform() * (ranges[t] - ranges[t-1]))\n",
    "            noisyCount = flag * delta + trueCount\n",
    "\n",
    "        else:\n",
    "            p = 1.0 - np.exp(-epsilon/2.0)\n",
    "            ext = np.random.geometric(p)\n",
    "            low = dst + ext * ladders[-1]\n",
    "            high = low + ladders[-1]\n",
    "            flag = -1.0\n",
    "            if (np.random.uniform()>0.5):\n",
    "                flag = 1.0\n",
    "            noisyCount = flag * np.random.randint(low, high+1) + trueCount\n",
    "        \n",
    "        errors.append(abs(noisyCount-trueCount)/trueCount)\n",
    "        \n",
    "    print(np.median(errors))\n",
    "    print(np.mean(errors), np.std(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
